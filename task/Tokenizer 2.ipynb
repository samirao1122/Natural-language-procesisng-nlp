{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6880e452-eb7a-4616-977d-5874cda0d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset=pd.read_csv(r\"C:\\Users\\wwrao\\Documents\\30 days of machine learning\\naive byes\\email_spam.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556d97e-872a-434b-8094-6c0282a73db3",
   "metadata": {},
   "source": [
    "## Sentence Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afc37dd8-5918-4ed7-87ec-c248b9604010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>?? the secrets to SUCCESS</td>\n",
       "      <td>Hi James,\\n\\nHave you claim your complimentary...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>?? You Earned 500 GCLoot Points</td>\n",
       "      <td>\\nalt_text\\nCongratulations, you just earned\\n...</td>\n",
       "      <td>not spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>?? Your GitHub launch code</td>\n",
       "      <td>Here's your GitHub launch code, @Mortyj420!\\n ...</td>\n",
       "      <td>not spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The Virtual Reward Center] Re: ** Clarifications</td>\n",
       "      <td>Hello,\\n \\nThank you for contacting the Virtua...</td>\n",
       "      <td>not spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-1 MLB Expert Inside, Plus Everything You Ne...</td>\n",
       "      <td>Hey Prachanda Rawal,\\n\\nToday's newsletter is ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                          ?? the secrets to SUCCESS   \n",
       "1                    ?? You Earned 500 GCLoot Points   \n",
       "2                         ?? Your GitHub launch code   \n",
       "3  [The Virtual Reward Center] Re: ** Clarifications   \n",
       "4  10-1 MLB Expert Inside, Plus Everything You Ne...   \n",
       "\n",
       "                                                text      type  \n",
       "0  Hi James,\\n\\nHave you claim your complimentary...      spam  \n",
       "1  \\nalt_text\\nCongratulations, you just earned\\n...  not spam  \n",
       "2  Here's your GitHub launch code, @Mortyj420!\\n ...  not spam  \n",
       "3  Hello,\\n \\nThank you for contacting the Virtua...  not spam  \n",
       "4  Hey Prachanda Rawal,\\n\\nToday's newsletter is ...      spam  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39901841-cc3a-4b67-905f-30b84af31856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f5e1ad-9b48-4af8-850b-6b328bf93e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [Hi James,\\n\\nHave you claim your complimentar...\n",
       "1     [\\nalt_text\\nCongratulations, you just earned\\...\n",
       "2     [Here's your GitHub launch code, @Mortyj420!, ...\n",
       "3     [Hello,\\n \\nThank you for contacting the Virtu...\n",
       "4     [Hey Prachanda Rawal,\\n\\nToday's newsletter is...\n",
       "                            ...                        \n",
       "79    [Dear Maryam, \\n\\n \\n\\nI would like to thank y...\n",
       "80    [Dear Customer,\\n\\nWelcome to Kilimall, Thanks...\n",
       "81    [Dear vladis163rus,\\nHere is the Steam Guard c...\n",
       "82    [View In Browser | Log in\\n \\n \\n\\nSkrill logo...\n",
       "83    [You've received a gift!, Sign in to your Bard...\n",
       "Name: text, Length: 84, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"text\"].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec304de-8d10-4143-bf72-c24f3d39c304",
   "metadata": {},
   "source": [
    "## word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "995d8b42-1db8-45c2-b908-9037759f2984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7463f59b-3395-488f-b184-82c5ad345220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [Hi, James, ,, Have, you, claim, your, complim...\n",
       "1     [alt_text, Congratulations, ,, you, just, earn...\n",
       "2     [Here, 's, your, GitHub, launch, code, ,, @, M...\n",
       "3     [Hello, ,, Thank, you, for, contacting, the, V...\n",
       "4     [Hey, Prachanda, Rawal, ,, Today, 's, newslett...\n",
       "                            ...                        \n",
       "79    [Dear, Maryam, ,, I, would, like, to, thank, y...\n",
       "80    [Dear, Customer, ,, Welcome, to, Kilimall, ,, ...\n",
       "81    [Dear, vladis163rus, ,, Here, is, the, Steam, ...\n",
       "82    [View, In, Browser, |, Log, in, Skrill, logo, ...\n",
       "83    [You, 've, received, a, gift, !, Sign, in, to,...\n",
       "Name: text, Length: 84, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"text\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272354d8-df26-441d-ad73-6bb6281ab5ae",
   "metadata": {},
   "source": [
    "## WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7410cae7-0ae9-44fa-a51c-92879bd61a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "token=WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06c07460-28dd-4089-9210-9316a3496d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [Hi, James, ,, Have, you, claim, your, complim...\n",
       "1     [alt_text, Congratulations, ,, you, just, earn...\n",
       "2     [Here, ', s, your, GitHub, launch, code, ,, @,...\n",
       "3     [Hello, ,, Thank, you, for, contacting, the, V...\n",
       "4     [Hey, Prachanda, Rawal, ,, Today, ', s, newsle...\n",
       "                            ...                        \n",
       "79    [Dear, Maryam, ,, I, would, like, to, thank, y...\n",
       "80    [Dear, Customer, ,, Welcome, to, Kilimall, ,, ...\n",
       "81    [Dear, vladis163rus, ,, Here, is, the, Steam, ...\n",
       "82    [View, In, Browser, |, Log, in, Skrill, logo, ...\n",
       "83    [You, ', ve, received, a, gift, !, Sign, in, t...\n",
       "Name: text, Length: 84, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"text\"].apply(lambda x:token.tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f91ce10-646a-4f0f-aade-3261c9b50dc2",
   "metadata": {},
   "source": [
    "## TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91a6c807-fef7-4d6c-806b-2b248f852c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tree=TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c95798e8-346a-49f5-bc0a-fc8f2efdce71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [Hi, James, ,, Have, you, claim, your, complim...\n",
       "1     [alt_text, Congratulations, ,, you, just, earn...\n",
       "2     [Here, 's, your, GitHub, launch, code, ,, @, M...\n",
       "3     [Hello, ,, Thank, you, for, contacting, the, V...\n",
       "4     [Hey, Prachanda, Rawal, ,, Today, 's, newslett...\n",
       "                            ...                        \n",
       "79    [Dear, Maryam, ,, I, would, like, to, thank, y...\n",
       "80    [Dear, Customer, ,, Welcome, to, Kilimall, ,, ...\n",
       "81    [Dear, vladis163rus, ,, Here, is, the, Steam, ...\n",
       "82    [View, In, Browser, |, Log, in, Skrill, logo, ...\n",
       "83    [You, 've, received, a, gift, !, Sign, in, to,...\n",
       "Name: text, Length: 84, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"text\"].apply(lambda x: tree.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bd502d-a894-4891-bdb9-e2026820792d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
