{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a703d6aa-7613-43d1-bd37-5f1ac7083302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4527b8b-605e-476e-9e74-ec039c559a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfe1259c-4bbb-455a-84cf-285bd064a77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x13d44ed4620>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f261a55-773b-42f9-9359-8edd3b7f6746",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = \"Hello! How are you? I'm learning NLP. Python.2.0 is great!!!\"\n",
    "\n",
    "\n",
    "doc = nlp(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e774c0e-64dc-445b-9563-b5109d678ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "!\n",
      "How\n",
      "are\n",
      "you\n",
      "?\n",
      "I\n",
      "'m\n",
      "learning\n",
      "NLP\n",
      ".\n",
      "Python.2.0\n",
      "is\n",
      "great\n",
      "!\n",
      "!\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "# Print tokens\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ff90f-c9e7-41ae-be8a-80b01c3fd328",
   "metadata": {},
   "source": [
    "## Working with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3591f7a3-2df8-4c27-8ce5-6470b8c03a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset=pd.read_csv(r\"C:\\Users\\wwrao\\Documents\\30 days of machine learning\\naive byes\\email_spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5e53ce8-2828-4197-8bee-b4200753a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    doc = nlp(text)  # Process text using spaCy\n",
    "    return [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "002c2734-ddf3-4cab-a409-0b7c04ce73e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [Hi, James, ,, \\n\\n, Have, you, claim, your, c...\n",
       "1     [\\n, alt_text, \\n, Congratulations, ,, you, ju...\n",
       "2     [Here, 's, your, GitHub, launch, code, ,, @Mor...\n",
       "3     [Hello, ,, \\n \\n, Thank, you, for, contacting,...\n",
       "4     [Hey, Prachanda, Rawal, ,, \\n\\n, Today, 's, ne...\n",
       "                            ...                        \n",
       "79    [Dear, Maryam, ,, \\n\\n \\n\\n, I, would, like, t...\n",
       "80    [Dear, Customer, ,, \\n\\n, Welcome, to, Kilimal...\n",
       "81    [Dear, vladis163rus, ,, \\n, Here, is, the, Ste...\n",
       "82    [View, In, Browser, |, Log, in, \\n \\n \\n\\n, Sk...\n",
       "83    [You, 've, received, a, gift, !, \\n, Sign, in,...\n",
       "Name: text, Length: 84, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"text\"].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f72dc10b-67ac-4b00-a95e-87374d9a4d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here',\n",
       " \"'s\",\n",
       " 'your',\n",
       " 'GitHub',\n",
       " 'launch',\n",
       " 'code',\n",
       " ',',\n",
       " '@Mortyj420',\n",
       " '!',\n",
       " '\\n \\n',\n",
       " 'an',\n",
       " 'octocat',\n",
       " 'standing',\n",
       " 'next',\n",
       " 'to',\n",
       " 'a',\n",
       " 'rocket',\n",
       " '\\n ',\n",
       " 'Continue',\n",
       " 'signing',\n",
       " 'up',\n",
       " 'for',\n",
       " 'GitHub',\n",
       " 'by',\n",
       " 'entering',\n",
       " 'the',\n",
       " 'code',\n",
       " 'below',\n",
       " ':',\n",
       " '\\n ',\n",
       " '63024610',\n",
       " '\\n \\n',\n",
       " 'Open',\n",
       " 'GitHub']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_text(dataset[\"text\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76780995-c764-4ba1-8f77-736ab7ddab02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
